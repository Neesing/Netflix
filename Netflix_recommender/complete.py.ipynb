{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyspark import SparkContext, SparkConf\n",
    "from pyspark.mllib.recommendation import ALS, MatrixFactorizationModel, Rating\n",
    "from time import time\n",
    "\n",
    "import math\n",
    "import sys\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "sc.stop()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading and Parsing Ratings data file in this function.Then we can parse the raw data into a new RDD\n",
    "def createRatingDataSet(sc, path):\n",
    "    print(\"Loading Rating Data \")\n",
    "\n",
    "    cleanedRatingData  = sc.textFile(path)\n",
    "    headerR = cleanedRatingData.take(1)[0]\n",
    "    ratingsData = cleanedRatingData.filter(lambda line: line!= headerR)\\\n",
    "        .map(lambda line: line.split(\",\")).map(lambda tokens : (tokens[0], tokens[1], tokens[2])).cache()\n",
    "\n",
    "    print(ratingsData.take(4))\n",
    "\n",
    "    print(\"Loading Rating Data Completed\")\n",
    "\n",
    "    return ratingsData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Loading and Parsing Movies data file.Then we can parse the raw data into a new RDD\n",
    "def createMovieDataSet(sc, path):\n",
    "    print(\"Loading Movie Data \")\n",
    "\n",
    "    cleanedMovieData = sc.textFile(path)\n",
    "    headerM = cleanedMovieData.take(1)[0]\n",
    "\n",
    "    moviesData = cleanedMovieData.filter(lambda line: line != headerM)\\\n",
    "        .map(lambda line: line.split(\",\")).map(lambda tokens : (tokens[0], tokens[2])).cache()\n",
    "\n",
    "    print(\"Loading Movie Data Completed\")\n",
    "\n",
    "    return moviesData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Splitting the rating data into training data,validation data and testing data.Ectracting the ratings to it RDD\n",
    "#Will determine the best ALS parameters using small dataset and then will use that for the entire dataset\n",
    "#Mapping to the ratings object(user,movieid,rating)\n",
    "\n",
    "def createTrainingTestingRDD(ratingData):    \n",
    "    trainingRDD, validationRDD, testRDD = ratingData.randomSplit([6, 2, 2])\n",
    "    predictValidationRDD = validationRDD.map(lambda x: (x[0], x[1]))\n",
    "    predictTestRDD = testRDD.map(lambda x: (x[0], x[1]))\n",
    "\n",
    "    return trainingRDD, validationRDD, testRDD, predictValidationRDD, predictTestRDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating and setting the parameters-rank,iterations and creating the model on the training data\n",
    "#Funtion to predict ratings for movies not rated by user\n",
    "#PredictAll takes an RDD of user id  and movie id pairs and predicts ratings for each pair\n",
    "\n",
    "def calculateBestRank(trainingRDD, predictValidationRDD, validationRDD, seed, iterations, regularization_parameter):\n",
    "    rankList = [4, 8, 12]\n",
    "    errors = [0, 0, 0]\n",
    "    err = 0\n",
    "    min_error = float('inf')\n",
    "    bestRank = -1\n",
    "\n",
    "    print (\"Loop Starts\")\n",
    "    for r in rankList:\n",
    "        learningModel = ALS.train(trainingRDD, r, seed=seed, iterations=iterations,lambda_=regularization_parameter)\n",
    "        predictions = learningModel.predictAll(predictValidationRDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "        ratePrediction = validationRDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "    \n",
    "        error = math.sqrt(ratePrediction.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "        errors[err] = error\n",
    "        err += 1\n",
    "        print ('Rank %s the RMSE is %s' % (r, error))\n",
    "        if error < min_error:\n",
    "            min_error = error\n",
    "            bestRank = r\n",
    "\n",
    "    print ('The best model was trained with rank %s' % bestRank)\n",
    "\n",
    "    predictions.take(3)\n",
    "\n",
    "    ratePrediction.take(3)\n",
    "\n",
    "    print (\"Loop Ends\")\n",
    "\n",
    "    return bestRank\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Prediction on test data and calculating the rmse for testing data\n",
    "\n",
    "def predictTestData(trainingRDD, predictTestRDD, testRDD, bestRank, seed, iterations, regularization_parameter):\n",
    "\n",
    "    model = ALS.train(trainingRDD, bestRank, seed=seed, iterations=iterations, lambda_=regularization_parameter)\n",
    "    predictions = model.predictAll(predictTestRDD).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    ratePrediction = testRDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "    error = math.sqrt(ratePrediction.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    \n",
    "    print ('For testing data the RMSE is %s' % (error))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is for fulldataset (training dataset) which includes all 4 files Combined_data1,Combined_data2,Combined_data3,Combined_data4\n",
    "#It is stored in S3 bucket in AWS but to test it in local machine, smaller set of data is taken due \n",
    "\n",
    "def createTrainigTestingFullRatingData(fullRatingData, seed, iterations, regularization_parameter, bestRank):\n",
    "\n",
    "    print (\" Full Rating Data Set Evaluation\")\n",
    "\n",
    "    trainingRDD, testRDD = fullRatingData.randomSplit([7, 3])\n",
    "    actualModel = ALS.train(trainingRDD, bestRank, seed=seed, \n",
    "                           iterations=iterations, lambda_=regularization_parameter)\n",
    "\n",
    "    predictTestRdd = testRDD.map(lambda x: (x[0], x[1]))\n",
    "    predictions = actualModel.predictAll(predictTestRdd).map(lambda r: ((r[0], r[1]), r[2]))\n",
    "    ratesPred = testRDD.map(lambda r: ((int(r[0]), int(r[1])), float(r[2]))).join(predictions)\n",
    "    error = math.sqrt(ratesPred.map(lambda r: (r[1][0] - r[1][1])**2).mean())\n",
    "    \n",
    "    print ('RMSE is %s' % (error))\n",
    "\n",
    "    return trainingRDD, testRDD, predictTestRDD\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadRatingData(sc, path):   \n",
    "    cleanedData =  sc.textFile(path)\n",
    "    headerR = cleanedData.take(1)[0]\n",
    "    fullRatingData = cleanedData.filter(lambda line: line!=headerR)\\\n",
    "                                .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),int(tokens[1]),float(tokens[2]))).cache()\n",
    "\n",
    "    return fullRatingData"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadMovieData(sc, path):                                          \n",
    "    cleanedData = sc.textFile(path)\n",
    "    headerM = cleanedData.take(1)[0]\n",
    "    movieData = cleanedData.filter(lambda line: line!=headerM)\\\n",
    "                                .map(lambda line: line.split(\",\")).map(lambda tokens: (int(tokens[0]),tokens[1],tokens[2])).cache()\n",
    "\n",
    "    movieTitle = movieData.map(lambda x: (int(x[0]),x[1]))\n",
    "\n",
    "    return movieData, movieTitle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "#this function is to count the number of ratings per movie, recommendation of movies is based on certain minimum number of ratings\n",
    "def getAverages(idRating):\n",
    "    n = len(idRating[1])\n",
    "    return idRating[0], (n, float(sum(x for x in idRating[1]))/n)\n",
    "\n",
    "\n",
    "def loadRDDForOperations(fullRatingData):\n",
    "    movieIDRatingsRDD = (fullRatingData.map(lambda x: (x[1], x[2])).groupByKey())\n",
    "    movieIDAvgRatingsRDD = movieIDRatingsRDD.map(getAverages)\n",
    "    movieRatingCountsRDD = movieIDAvgRatingsRDD.map(lambda x: (x[0], x[1][0]))\n",
    "\n",
    "    return movieRatingCountsRDD"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gettestData(path):\n",
    "\n",
    "    with open(path) as f:\n",
    "       new_user_ratings = [tuple(map(int, i.split(','))) for i in f]\n",
    "    print(new_user_ratings)\n",
    "\n",
    "    return new_user_ratings\n",
    "\n",
    "#Creating the model on the full training data\n",
    "def createNewModel(completeRatingData, seed, iterations, regularization_parameter, bestRank):\n",
    "\n",
    "    t0 = time()\n",
    "    model = ALS.train(completeRatingData, bestRank, seed=seed, \n",
    "                              iterations=iterations, lambda_=regularization_parameter)\n",
    "    tt = time() - t0\n",
    "\n",
    "    print (\"Training time %s seconds\" % round(tt,3))\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Recommending top movies with reviews more than 25\n",
    "def transformAndPredictTopMovies(userRecommendationRDD, movieRatingCountRDD, movieTitle):\n",
    "    recommendationRatingData = userRecommendationRDD.map(lambda x: (x.product, x.rating))\n",
    "    ratingtitleCountRDD = \\\n",
    "        recommendationRatingData.join(movieTitle).join(movieRatingCountRDD)\n",
    "    ratingtitleCountRDD.take(3)\n",
    "\n",
    "    ratingtitleCountRDD = \\\n",
    "        ratingtitleCountRDD.map(lambda r: (r[1][0][1], r[1][0][0], r[1][1]))\n",
    "    \n",
    "    topMovies = ratingtitleCountRDD.filter(lambda r: r[2]>=25).takeOrdered(25, key=lambda x: -x[1])\n",
    "\n",
    "    print ('Movies Top :\\n%s' % '\\n'.join(map(str, topMovies)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Process of Learning Starts\n",
      "Loading Rating Data \n",
      "[('1', '1488844', '3'), ('1', '822109', '5'), ('1', '885013', '4'), ('1', '30878', '4')]\n",
      "Loading Rating Data Completed\n",
      "Loading Movie Data \n",
      "Loading Movie Data Completed\n",
      "Loop Starts\n",
      "Rank 4 the RMSE is 2.137232551500581\n",
      "Rank 8 the RMSE is 2.0211619603305677\n",
      "Rank 12 the RMSE is 2.0876032959479165\n",
      "The best model was trained with rank 8\n",
      "Loop Ends\n",
      "For testing data the RMSE is 1.8901958648914603\n",
      "Implementation\n",
      "Rating count  59999  in the  dataset\n",
      " Full Rating Data Set Evaluation\n",
      "RMSE is 1.8595482505170389\n",
      "There are 17769 movies in the complete dataset\n",
      "[(0, 260, 9), (0, 1, 8), (0, 16, 7), (0, 25, 8), (0, 32, 9), (0, 335, 4), (0, 379, 3), (0, 296, 7), (0, 858, 10), (0, 50, 8)]\n",
      "New user ratings: [(0, 260, 9), (0, 1, 8), (0, 16, 7), (0, 25, 8), (0, 32, 9), (0, 335, 4), (0, 379, 3), (0, 296, 7), (0, 858, 10), (0, 50, 8)]\n",
      "Training time 9.591 seconds\n",
      "Movies Top :\n",
      "\n",
      "[Rating(user=0, product=15420, rating=-0.5933931794005765), Rating(user=0, product=3184, rating=-0.35854608836220736)]\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "0",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2918: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    print ('Process of Learning Starts')\n",
    "\n",
    "    conf = SparkConf().setAppName(\"NetFlix Prediction\").set(\"spark.executor.memory\", \"12g\").set(\"spark.driver.memory\", \"12g\")\n",
    "    sc = SparkContext()\n",
    "   \n",
    "    #To run it on AWS\n",
    "#     rating_data_path = 's3://project-test-n/rank/output1.csv'\n",
    "#     movie_data_path = 's3://project-test-n/movie_titles.csv'\n",
    "#     complete_data_path = 's3://project-test-n/cleaned/output-rating.csv'\n",
    "#     test_path = '/tmp/netflix-test.txt'\n",
    "\n",
    "    \n",
    "    #To run it locally\n",
    "    rating_data_path = 'C:/Users/User/Netflix_dataset/sample_data.csv'\n",
    "    movie_data_path = 'C:/Users/User/Netflix_dataset/movie_titles.csv'\n",
    "    complete_data_path = 'C:/Users/User/Netflix_dataset/sample_data2.csv'\n",
    "\n",
    "    test_path = 'C:/Users/User/Netflix_dataset/netflix-test.txt'\n",
    "\n",
    "    seed = 5\n",
    "    iterations = 10\n",
    "    regularization_parameter = 0.1\n",
    "    new_user_ID = 0\n",
    "\n",
    "    ratingData = createRatingDataSet(sc, rating_data_path)\n",
    "    movieData =  createMovieDataSet(sc, movie_data_path)\n",
    "\n",
    "    trainingRDD, validationRDD, testingRDD, predictValidationRDD, predictTestRDD = createTrainingTestingRDD(ratingData)\n",
    "\n",
    "    bestRank = calculateBestRank(trainingRDD, predictValidationRDD, validationRDD, seed, iterations, regularization_parameter)\n",
    "\n",
    "    predictTestData(trainingRDD, predictTestRDD, testingRDD, bestRank, seed, iterations, regularization_parameter)\n",
    "\n",
    "    print (\"Implementation\")\n",
    "\n",
    "    fullRatingData = loadRatingData(sc, complete_data_path)\n",
    "\n",
    "    print (\"Rating count  %s  in the  dataset\" % (fullRatingData.count()))\n",
    "\n",
    "    comtrainingRDD, comtestRDD, compredictTestRDD = createTrainigTestingFullRatingData(fullRatingData, seed, iterations, regularization_parameter, bestRank)\n",
    "\n",
    "    completeMovieData, movieTitle = loadMovieData(sc, movie_data_path)\n",
    "\n",
    "    print (\"There are %s movies in the complete dataset\" % (completeMovieData.count()))\n",
    "\n",
    "    testUserRating = gettestData(test_path)\n",
    "    testUserRatingRDD = sc.parallelize(testUserRating)\n",
    "    print ('New user ratings: %s' % testUserRatingRDD.take(10))\n",
    "\n",
    "    completeRatingData = fullRatingData.union(testUserRatingRDD)\n",
    "\n",
    "    model = createNewModel(completeRatingData, seed, iterations, regularization_parameter, bestRank)\n",
    "\n",
    "    testUserRatingId = map(lambda x: x[1], testUserRating)\n",
    "\n",
    "    UnratedMovieId = (completeMovieData.filter(lambda x: x[0] not in testUserRatingId).map(lambda x: (new_user_ID, x[0])))\n",
    "\n",
    "    userRecommendationRDD = model.predictAll(UnratedMovieId)\n",
    "\n",
    "    completeMovieTitle = movieData.map(lambda x: (int(x[0]),x[1]))\n",
    "\n",
    "    movieRatingCountsRDD = loadRDDForOperations(fullRatingData)\n",
    "\n",
    "    transformAndPredictTopMovies(userRecommendationRDD, movieRatingCountsRDD, movieTitle)\n",
    "\n",
    "    my_movie = sc.parallelize([(0, 500)]) \n",
    "    individualMovieRatingRDD = model.predictAll(UnratedMovieId)\n",
    "    print(individualMovieRatingRDD.take(2))\n",
    "\n",
    "    sys.exit(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
